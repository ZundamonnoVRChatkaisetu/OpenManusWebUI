import json
from typing import Any, List, Literal

from pydantic import Field

from app.agent.react import ReActAgent
from app.logger import logger
from app.prompt.toolcall import NEXT_STEP_PROMPT, SYSTEM_PROMPT
from app.schema import AgentState, Message, ToolCall
from app.tool import CreateChatCompletion, Terminate, ToolCollection


TOOL_CALL_REQUIRED = "Tool calls required but none provided"


class ToolCallAgent(ReActAgent):
    """Base agent class for handling tool/function calls with enhanced abstraction"""

    name: str = "toolcall"
    description: str = "an agent that can execute tool calls."

    system_prompt: str = SYSTEM_PROMPT
    next_step_prompt: str = NEXT_STEP_PROMPT

    available_tools: ToolCollection = ToolCollection(
        CreateChatCompletion(), Terminate()
    )
    tool_choices: Literal["none", "auto", "required"] = "auto"
    special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])

    tool_calls: List[ToolCall] = Field(default_factory=list)

    max_steps: int = 100  # max_stepsã‚’30ã‹ã‚‰100ã«å¢—åŠ 
    
    # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    step_review_interval: int = 5  # ä½•ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«é€²æ—ã‚’ç¢ºèªã™ã‚‹ã‹
    adaptive_planning: bool = True  # çŠ¶æ³ã«å¿œã˜ã¦è¨ˆç”»ã‚’èª¿æ•´ã™ã‚‹ã‹
    verbose_thinking: bool = True   # è©³ç´°ãªæ€è€ƒãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹

    async def think(self) -> bool:
        """Process current state and decide next actions using tools"""
        # ã‚¹ãƒ†ãƒƒãƒ—ã«å¿œã˜ãŸè‡ªå·±è©•ä¾¡ã¨è¨ˆç”»èª¿æ•´
        if self.adaptive_planning and self.current_step > 0 and self.current_step % self.step_review_interval == 0:
            await self._review_progress()
        
        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
        if self.next_step_prompt:
            # é•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å ´åˆã¯æœ€é©åŒ–ï¼ˆé‡è¦ãªæŒ‡ç¤ºã‚’ä¿æŒï¼‰
            effective_prompt = self._optimize_next_step_prompt() if len(self.next_step_prompt) > 500 else self.next_step_prompt
            user_msg = Message.user_message(effective_prompt)
            self.messages += [user_msg]

        # æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ­ã‚°è¨˜éŒ²
        if self.verbose_thinking:
            logger.info(f"ğŸ’­ Step {self.current_step}: æ€è€ƒé–‹å§‹ - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ç´„{self._estimate_context_length()}æ–‡å­—")

        # Get response with tool options
        response = await self.llm.ask_tool(
            messages=self.messages,
            system_msgs=[Message.system_message(self.system_prompt)]
            if self.system_prompt
            else None,
            tools=self.available_tools.to_params(),
            tool_choice=self.tool_choices,
        )
        self.tool_calls = response.tool_calls

        # Log response info
        logger.info(f"âœ¨ {self.name}'s thoughts: {response.content}")
        logger.info(
            f"ğŸ› ï¸ {self.name} selected {len(response.tool_calls) if response.tool_calls else 0} tools to use"
        )
        if response.tool_calls:
            logger.info(
                f"ğŸ§° Tools being prepared: {[call.function.name for call in response.tool_calls]}"
            )

        try:
            # Handle different tool_choices modes
            if self.tool_choices == "none":
                if response.tool_calls:
                    logger.warning(
                        f"ğŸ¤” Hmm, {self.name} tried to use tools when they weren't available!"
                    )
                if response.content:
                    self.memory.add_message(Message.assistant_message(response.content))
                    return True
                return False

            # Create and add assistant message
            assistant_msg = (
                Message.from_tool_calls(
                    content=response.content, tool_calls=self.tool_calls
                )
                if self.tool_calls
                else Message.assistant_message(response.content)
            )
            self.memory.add_message(assistant_msg)

            if self.tool_choices == "required" and not self.tool_calls:
                return True  # Will be handled in act()

            # For 'auto' mode, continue with content if no commands but content exists
            if self.tool_choices == "auto" and not self.tool_calls:
                return bool(response.content)

            return bool(self.tool_calls)
        except Exception as e:
            logger.error(f"ğŸš¨ Oops! The {self.name}'s thinking process hit a snag: {e}")
            self.memory.add_message(
                Message.assistant_message(
                    f"Error encountered while processing: {str(e)}"
                )
            )
            return False

    async def act(self) -> str:
        """Execute tool calls and handle their results"""
        if not self.tool_calls:
            if self.tool_choices == "required":
                raise ValueError(TOOL_CALL_REQUIRED)

            # Return last message content if no tool calls
            return self.messages[-1].content or "No content or commands to execute"

        results = []
        for command in self.tool_calls:
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå‰ã®ãƒ­ã‚°è¨˜éŒ²ï¼ˆè©³ç´°ãƒ¢ãƒ¼ãƒ‰ï¼‰
            if self.verbose_thinking:
                logger.info(f"ğŸ”§ ãƒ„ãƒ¼ãƒ« '{command.function.name}' ã®å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™...")
                
            result = await self.execute_tool(command)
            logger.info(
                f"ğŸ¯ Tool '{command.function.name}' completed its mission! Result: {result[:100]}..." if len(result) > 100 else result
            )

            # Add tool response to memory
            tool_msg = Message.tool_message(
                content=result, tool_call_id=command.id, name=command.function.name
            )
            self.memory.add_message(tool_msg)
            results.append(result)

        # å„å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—å¾Œã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã‚’ç¢ºèª
        if self.verbose_thinking:
            msg_count = len(self.memory.messages)
            ctx_len = self._estimate_context_length()
            logger.info(f"ğŸ“Š å®Ÿè¡Œå¾Œã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹: {msg_count}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, ç´„{ctx_len}æ–‡å­—")

        return "\n\n".join(results)

    async def execute_tool(self, command: ToolCall) -> str:
        """Execute a single tool call with robust error handling"""
        if not command or not command.function or not command.function.name:
            return "Error: Invalid command format"

        name = command.function.name
        if name not in self.available_tools.tool_map:
            return f"Error: Unknown tool '{name}'"

        try:
            # Parse arguments
            args = json.loads(command.function.arguments or "{}")

            # Execute the tool
            logger.info(f"ğŸ”§ Activating tool: '{name}'...")
            result = await self.available_tools.execute(name=name, tool_input=args)

            # Format result for display
            observation = (
                f"Observed output of cmd `{name}` executed:\n{str(result)}"
                if result
                else f"Cmd `{name}` completed with no output"
            )

            # Handle special tools like `finish`
            await self._handle_special_tool(name=name, result=result)

            return observation
        except json.JSONDecodeError:
            error_msg = f"Error parsing arguments for {name}: Invalid JSON format"
            logger.error(
                f"ğŸ“ Oops! The arguments for '{name}' don't make sense - invalid JSON, arguments:{command.function.arguments}"
            )
            return f"Error: {error_msg}"
        except Exception as e:
            error_msg = f"âš ï¸ Tool '{name}' encountered a problem: {str(e)}"
            logger.error(error_msg)
            return f"Error: {error_msg}"

    async def _handle_special_tool(self, name: str, result: Any, **kwargs):
        """Handle special tool execution and state changes"""
        if not self._is_special_tool(name):
            return

        if self._should_finish_execution(name=name, result=result, **kwargs):
            # Set agent state to finished
            logger.info(f"ğŸ Special tool '{name}' has completed the task!")
            self.state = AgentState.FINISHED

    @staticmethod
    def _should_finish_execution(**kwargs) -> bool:
        """Determine if tool execution should finish the agent"""
        return True

    def _is_special_tool(self, name: str) -> bool:
        """Check if tool name is in special tools list"""
        return name.lower() in [n.lower() for n in self.special_tool_names]
    
    async def _review_progress(self) -> None:
        """å®šæœŸçš„ãªé€²æ—ç¢ºèªã¨æˆ¦ç•¥ã®èª¿æ•´"""
        logger.info(f"ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—{self.current_step}: é€²æ—ç¢ºèªã¨æˆ¦ç•¥ã®èª¿æ•´")
        
        # é€²æ—ã®è¦ç´„
        summary = f"ç¾åœ¨ã€ã‚¹ãƒ†ãƒƒãƒ—{self.current_step}/{self.max_steps}ã‚’å®Ÿè¡Œä¸­ã§ã™ã€‚"
        
        # ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã‚’åˆ†æ
        memory_analysis = self._analyze_memory_state()
        
        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã™ã‚‹é€²æ—ç¢ºèªæƒ…å ±
        progress_note = f"\n\n# é€²æ—ç¢ºèªï¼ˆã‚¹ãƒ†ãƒƒãƒ—{self.current_step}ï¼‰\n{summary}\n{memory_analysis}\n\n"
        
        # æ ¹æœ¬çš„ãªå•é¡Œè§£æ±ºã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹æŒ‡ç¤ºã‚’è¿½åŠ 
        focus_instruction = "ã“ã‚Œã¾ã§ã®é€²æ—ã‚’è¸ã¾ãˆã€å•é¡Œã®æ ¹æœ¬çš„ãªè§£æ±ºã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚"
        
        # next_step_promptãŒã‚ã‚‹å ´åˆã¯æœ«å°¾ã«è¿½åŠ ã€ãªã„å ´åˆã¯æ–°ãŸã«è¨­å®š
        if self.next_step_prompt:
            self.next_step_prompt += progress_note + focus_instruction
        else:
            self.next_step_prompt = progress_note + focus_instruction
    
    def _analyze_memory_state(self) -> str:
        """ãƒ¡ãƒ¢ãƒªã®çŠ¶æ…‹ã‚’åˆ†æã—ã€é©åˆ‡ãªæˆ¦ç•¥èª¿æ•´ã®ãŸã‚ã®æƒ…å ±ã‚’æä¾›"""
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç·æ•°
        msg_count = len(self.memory.messages)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°ã®æŒ‡ç¤ºã‚’å–å¾—
        last_user_msg = None
        for msg in reversed(self.memory.messages):
            if msg.role == "user":
                last_user_msg = msg.content
                break
        
        # å®Ÿè¡Œæ¸ˆã¿ã®ãƒ„ãƒ¼ãƒ«ã‚’é›†è¨ˆ
        tool_usage = {}
        for msg in self.memory.messages:
            if msg.role == "tool" and msg.name:
                tool_usage[msg.name] = tool_usage.get(msg.name, 0) + 1
        
        # åˆ†æçµæœã®æ§‹ç¯‰
        analysis = [
            f"- ä¼šè©±å±¥æ­´: {msg_count}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
            f"- æ¨å®šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: ç´„{self._estimate_context_length()}æ–‡å­—"
        ]
        
        if tool_usage:
            tools_str = ", ".join([f"{name}({count}å›)" for name, count in tool_usage.items()])
            analysis.append(f"- ä½¿ç”¨ãƒ„ãƒ¼ãƒ«: {tools_str}")
        
        if last_user_msg:
            # é•·ã™ãã‚‹å ´åˆã¯è¦ç´„
            if len(last_user_msg) > 100:
                last_user_msg = last_user_msg[:100] + "..."
            analysis.append(f"- æœ€æ–°ã®æŒ‡ç¤º: {last_user_msg}")
        
        return "\n".join(analysis)
    
    def _optimize_next_step_prompt(self) -> str:
        """é•·ã„next_step_promptã‚’æœ€é©åŒ–ã—ã¦é‡è¦ãªéƒ¨åˆ†ã‚’ä¿æŒ"""
        if not self.next_step_prompt or len(self.next_step_prompt) <= 500:
            return self.next_step_prompt
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹é€ ã‚’åˆ†æ
        prompt = self.next_step_prompt
        
        # é‡è¦ãªæŒ‡ç¤ºã‚’æ¤œå‡ºï¼ˆå…ˆé ­éƒ¨åˆ†ã¨#ã¾ãŸã¯*ã§å§‹ã¾ã‚‹è¡Œã‚’ä¿æŒï¼‰
        lines = prompt.split("\n")
        important_lines = []
        
        # å…ˆé ­ã®æ•°è¡Œã¯å¸¸ã«ä¿æŒ
        header_lines = min(3, len(lines) // 4)
        important_lines.extend(lines[:header_lines])
        
        # é‡è¦ãªæŒ‡ç¤ºï¼ˆ#ã¾ãŸã¯*ã§å§‹ã¾ã‚‹è¡Œï¼‰ã‚’æ¤œå‡º
        for line in lines[header_lines:]:
            stripped = line.strip()
            if stripped.startswith(("#", "*", "-", "1.", "2.", "3.", ">")):
                important_lines.append(line)
            elif "æ³¨æ„" in line or "é‡è¦" in line or "å¿…é ˆ" in line:
                important_lines.append(line)
        
        # æœ«å°¾ã®æŒ‡ç¤ºã‚‚é‡è¦ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã®ã§ä¿æŒ
        if len(lines) > header_lines + len(important_lines):
            footer_lines = min(3, len(lines) // 5)
            important_lines.extend(lines[-footer_lines:])
        
        # æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        if len(important_lines) < len(lines) // 2:
            optimized = "\n".join(important_lines)
            # é‡è¦éƒ¨åˆ†ã®é–“ã«çœç•¥ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™
            if header_lines > 0 and len(important_lines) > header_lines:
                header = "\n".join(important_lines[:header_lines])
                rest = "\n".join(important_lines[header_lines:])
                optimized = f"{header}\n...(ä¸­ç•¥)...\n{rest}"
            return optimized
        
        # ååˆ†ãªæœ€é©åŒ–ãŒã§ããªã„å ´åˆã¯å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™
        return prompt
    
    def _estimate_context_length(self) -> int:
        """ä¼šè©±å±¥æ­´ã®ãŠãŠã‚ˆãã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ï¼ˆæ–‡å­—æ•°ï¼‰ã‚’æ¨å®š"""
        total_chars = 0
        for msg in self.memory.messages:
            # contentéƒ¨åˆ†ã®é•·ã•
            if msg.content:
                total_chars += len(msg.content)
            
            # tool_callséƒ¨åˆ†ã®é•·ã•ã‚’æ¨å®š
            if msg.tool_calls:
                for call in msg.tool_calls:
                    # function.nameã¨argumentsã®é•·ã•ã‚’åŠ ç®—
                    total_chars += len(call.function.name) + len(call.function.arguments or "")
                    # ãã®ä»–ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®é•·ã•ã‚‚è€ƒæ…®
                    total_chars += 50  # id, typeãªã©ã‚’å«ã‚€æ¦‚ç®—
            
            # ãƒ­ãƒ¼ãƒ«ã‚„åå‰ãªã©ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†ã‚‚åŠ ç®—
            total_chars += 20  # å½¹å‰²ã‚„åå‰ã®ãŸã‚ã®è¿½åŠ æ–‡å­—æ•°
        
        return total_chars
