# Global LLM configuration
[llm]
model = "gpt-3.5-turbo" # LM Studioの場合、ローカルモデル名
base_url = "http://localhost:1234/v1" # LMStudioのAPIエンドポイント
api_key = "sk-no-key-required" # LM Studioの場合は任意の値
max_tokens = 8192  # 4096から8192に増加
temperature = 0.0
api_type = "openai" # LM Studioの場合はopenai
api_version = "" # LM Studioの場合は空文字

# [llm] #AZURE OPENAI:
# api_type= 'azure'
# model = "YOUR_MODEL_NAME" #"gpt-4o-mini"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPOLYMENT_ID}"
# api_key = "AZURE API KEY"
# max_tokens = 8192  # 8096から8192に統一
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "gpt-4-vision-preview"
base_url = "http://localhost:1234/v1"
api_key = "sk-no-key-required"
api_type = "openai"
api_version = ""
